import { NextResponse } from 'next/server';
import { getDb } from '@/app/lib/mongodb';

export async function POST(request: Request) {
  console.log('=== BASIC TEST: POST request received ===');
  console.log('Time:', new Date().toISOString());
  console.log('üöÄ /api/ai/stream endpoint hit!');
  
  try {
    console.log('üîç About to parse request body...');
    const { user_query, chat_id, user_id } = await request.json();
    console.log('‚úÖ Request body parsed successfully');
    
    console.log('üìù Request payload:', { 
      user_query, 
      chat_id, 
      user_id,
      timestamp: new Date().toISOString()
    });
    
    if (!user_query) {
      console.error('‚ùå Missing user_query in request');
      return NextResponse.json({ error: 'user_query is required' }, { status: 400 });
    }

    // Save user message to database if chat_id is provided
    if (chat_id) {
      console.log('üíæ Saving user message to database...');
      const db = await getDb();
      await db.collection('messages').insertOne({
        chat_id: chat_id,
        user_id: user_id,
        text: user_query,
        role: 'user',
        type: 'text',
        created_at: new Date()
      });
      console.log('‚úÖ User message saved to database');
    } else {
      console.log('‚ö†Ô∏è No chat_id provided, skipping database save');
    }

    // Forward request to local AI API on port 8000
    console.log('üîÑ Attempting to connect to AI service on localhost:8000...');
    console.log('üì§ Sending payload to AI service:', { user_query, chat_id, user_id });
    
    const aiResponse = await fetch('http://localhost:8000/api/ai/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'text/event-stream',
      },
      body: JSON.stringify({
        user_query,
        chat_id,
        user_id
      }),
    });

    console.log('üìä AI service response status:', aiResponse.status);
    console.log('üìã AI service response headers:', Object.fromEntries(aiResponse.headers.entries()));
    
    if (!aiResponse.ok) {
      console.error(`‚ùå AI API responded with status: ${aiResponse.status}`);
      const errorText = await aiResponse.text();
      console.error('üí• AI API error response:', errorText);
      throw new Error(`AI API responded with status: ${aiResponse.status} - ${errorText}`);
    }

    console.log('‚úÖ AI service connection successful, starting stream...');

    // Create a transform stream to handle the AI response and save to database
    const encoder = new TextEncoder();
    const decoder = new TextDecoder();
    let fullAIResponse = '';
    let chunkCount = 0;

    const stream = new ReadableStream({
      async start(controller) {
        console.log('üåä Stream started');
        const reader = aiResponse.body?.getReader();
        
        if (!reader) {
          console.error('‚ùå No response stream available from AI service');
          controller.enqueue(encoder.encode(`data: ${JSON.stringify({ 
            type: "thought_stream", 
            message: "No response stream available", 
            final: true 
          })}\n\n`));
          controller.close();
          return;
        }

        try {
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              console.log('üèÅ Stream finished');
              console.log('üìù Full AI response length:', fullAIResponse.length);
              
              // Save complete AI response to database if chat_id is provided
              if (chat_id && fullAIResponse) {
                console.log('üíæ Saving AI response to database...');
                const db = await getDb();
                await db.collection('messages').insertOne({
                  chat_id: chat_id,
                  user_id: user_id,
                  text: fullAIResponse,
                  role: 'assistant',
                  type: 'text',
                  created_at: new Date()
                });
                console.log('‚úÖ AI response saved to database');
              }
              
              controller.enqueue(encoder.encode(`data: [DONE]\n\n`));
              controller.close();
              break;
            }

            chunkCount++;
            console.log(`üì¶ Processing chunk ${chunkCount}`);
            
            // Decode the chunk from AI API
            const chunk = decoder.decode(value, { stream: true });
            console.log(`üîç Chunk ${chunkCount} content:`, chunk.substring(0, 100) + (chunk.length > 100 ? '...' : ''));
            
            // Forward the chunk directly to the client
            controller.enqueue(value);
            
            // Extract message content for database storage
            const lines = chunk.split('\n');
            for (const line of lines) {
              if (line.startsWith('data: ')) {
                try {
                  const jsonStr = line.slice(6).trim();
                  if (jsonStr !== '[DONE]' && jsonStr !== '') {
                    const data = JSON.parse(jsonStr);
                    console.log(`üìã Parsed data:`, data);
                    if (data.type === 'thought_stream' && data.message) {
                      fullAIResponse += data.message;
                    }
                  }
                } catch (e: any) {
                  console.warn(`‚ö†Ô∏è Could not parse chunk line: ${line}`, e.message);
                }
              }
            }
          }
        } catch (error) {
          console.error('üí• Error reading AI stream:', error);
          controller.enqueue(encoder.encode(`data: ${JSON.stringify({ 
            type: "thought_stream", 
            message: "Stream error occurred", 
            final: true 
          })}\n\n`));
          controller.close();
        }
      }
    });

    console.log('üì° Returning stream response to client');
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST',
        'Access-Control-Allow-Headers': 'Content-Type',
      },
    });

  } catch (error: any) {
    console.error('üí• Error in /api/ai/stream:', error);
    console.error('üîç Error details:', {
      message: error.message,
      stack: error.stack,
      name: error.name
    });
    
    // Fallback response if local AI API is not available
    const encoder = new TextEncoder();
    const fallbackStream = new ReadableStream({
      start(controller) {
        console.log('üÜò Sending fallback response');
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({ 
          type: "thought_stream",
          message: "I'm having trouble connecting to the AI service. Please make sure the AI API is running on localhost:8000.",
          final: true
        })}\n\n`));
        controller.enqueue(encoder.encode(`data: [DONE]\n\n`));
        controller.close();
      }
    });

    return new Response(fallbackStream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    });
  }
} 